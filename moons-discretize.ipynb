{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d89dfd5-7692-45bc-b126-862b3cb0c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.datasets as skd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47025183-b6df-4c37-abb4-545e4343b991",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 215\u001b[0m\n\u001b[1;32m    212\u001b[0m X\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mconcatenate([data, data4impute], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    214\u001b[0m model \u001b[38;5;241m=\u001b[39m MaskingTreesModel(n_bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m--> 215\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m data_fake \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m);\n\u001b[1;32m    220\u001b[0m nimp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# number of imputations needed\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[38], line 95\u001b[0m, in \u001b[0;36mMaskingTreesModel.fit\u001b[0;34m(self, X, quantize_cols)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantize_cols_ \u001b[38;5;241m=\u001b[39m quantize_cols\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m quantize_cols \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloating\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, pd\u001b[38;5;241m.\u001b[39mDataFrame)\n\u001b[1;32m     96\u001b[0m     q_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(X\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloating\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantize_cols_ \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;129;01min\u001b[39;00m q_cols \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(X\u001b[38;5;241m.\u001b[39mcolumns)]\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.utils.deprecation import _deprecate_Xt_in_inverse_transform\n",
    "from sklearn.utils.validation import (\n",
    "    _check_feature_names_in,\n",
    "    _check_sample_weight,\n",
    "    check_array,\n",
    "    check_is_fitted,\n",
    ")\n",
    "class KBinsDiscretizerSampler(KBinsDiscretizer):\n",
    "    def inverse_transform_sample(self, X=None, random_state=None):\n",
    "        rng = check_random_state(random_state)\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        if \"onehot\" in self.encode:\n",
    "            X = self._encoder.inverse_transform(X)\n",
    "\n",
    "        Xinv = check_array(X, copy=True, dtype=(np.float64, np.float32))\n",
    "        n_features = self.n_bins_.shape[0]\n",
    "        if Xinv.shape[1] != n_features:\n",
    "            raise ValueError(\n",
    "                \"Incorrect number of features. Expecting {}, received {}.\".format(\n",
    "                    n_features, Xinv.shape[1]\n",
    "                )\n",
    "            )\n",
    "        n = X.shape[0]\n",
    "        for jj in range(n_features):\n",
    "            jitter = rng.uniform(0., 1., size=n)\n",
    "            bin_edges = self.bin_edges_[jj]\n",
    "            bin_centers = (bin_edges[1:] + bin_edges[:-1]) * 0.5\n",
    "            bin_lefts = bin_edges[1:][(Xinv[:, jj]).astype(np.int64)]\n",
    "            bin_rights = bin_edges[:-1][(Xinv[:, jj]).astype(np.int64)]\n",
    "            Xinv[:, jj] = bin_lefts * jitter + bin_rights * (1 - jitter)\n",
    "\n",
    "        return Xinv\n",
    "\n",
    "def top_p_sampling(n_bins, probs, rng, top_p):\n",
    "    \"\"\" This implements a modified version of nucleus sampling.\n",
    "    It discards probability mass beyond the boundary of the class straddles the top_p boundary,\n",
    "    but it does not discard the probability mass of this class below the boundary.\n",
    "    \"\"\"\n",
    "    probs = probs.ravel()  # currently assumes only one sample\n",
    "    sort_indices = np.argsort(probs)[::-1]\n",
    "    sort_probs = probs[sort_indices]\n",
    "    cumsum_probs = np.cumsum(sort_probs)\n",
    "    unnorm_probs = np.diff(np.minimum(cumsum_probs, top_p), prepend=0.)\n",
    "    unnorm_probs = unnorm_probs[np.argsort(sort_indices)]  # undo the sort\n",
    "    norm_probs = unnorm_probs / np.sum(unnorm_probs)\n",
    "    \n",
    "    chosen = np.array(rng.choice(n_bins, p=norm_probs))\n",
    "    return chosen\n",
    "\n",
    "class MaskingTreesModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_bins=5,\n",
    "        duplicate_K=50,\n",
    "        top_p=0.9,\n",
    "        random_state = None,\n",
    "    ):\n",
    "        self.n_bins = n_bins\n",
    "        self.duplicate_K = duplicate_K\n",
    "        self.top_p = top_p\n",
    "        self.random_state = random_state\n",
    "\n",
    "        assert 2 <= n_bins\n",
    "        assert 1 <= duplicate_K\n",
    "        assert 0 < top_p <= 1\n",
    "    \n",
    "        self.xgbers_ = None\n",
    "        self.quantize_cols_ = None\n",
    "        self.quantizers_ = None\n",
    "        self.X_ = None\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X,\n",
    "        quantize_cols='floating',\n",
    "    ):\n",
    "        # TODO - handle categorical columns\n",
    "        # TODO - xgboost iterator - generate batches on the fly\n",
    "        # TODO - xgboost kwargs\n",
    "        # TODO - sample_weight from OADM formula\n",
    "        # TODO - KDITransformer\n",
    "        rng = check_random_state(self.random_state)\n",
    "        n_samples, n_dims = X.shape\n",
    "        if isinstance(quantize_cols, list):\n",
    "            assert len(quantize_cols) == n_dims\n",
    "            self.quantize_cols_ = quantize_cols\n",
    "        elif quantize_cols == 'floating':\n",
    "            assert isinstance(X, pd.DataFrame)\n",
    "            q_cols = list(X.select_dtypes(include='floating').columns)\n",
    "            self.quantize_cols_ = [col in q_cols for col in list(X.columns)]\n",
    "        elif quantize_cols == 'number':\n",
    "            assert isinstance(X, pd.DataFrame)\n",
    "            q_cols = list(X.select_dtypes(include='number').columns)\n",
    "            self.quantize_cols_ = [col in q_cols for col in list(X.columns)]    \n",
    "        elif quantize_cols == 'none':\n",
    "            self.quantize_cols_ = [False] * n_dims\n",
    "        elif quantize_cols == 'all':\n",
    "            self.quantize_cols_ = [True] * n_dims\n",
    "        else:\n",
    "            raise ValueError(f'unexpected quantize_cols: {quantize_cols}')\n",
    "\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "            self.X_ = X.copy()\n",
    "        elif isinstance(X, np.ndarray):\n",
    "            self.X_ = X.copy()\n",
    "        else:\n",
    "            raise ValueError(f'X must be np.ndarray or pd.DataFrame: {type(X)}')\n",
    "        \n",
    "        self.quantizers_ = []       \n",
    "        for d in range(n_dims):\n",
    "            if self.quantize_cols_[d]:\n",
    "                curq = KBinsDiscretizerSampler(\n",
    "                    n_bins=self.n_bins, encode='ordinal', strategy='quantile')\n",
    "                print(X[:, d])\n",
    "                curq.fit(X[~np.isnan(X[:, d]), d:d+1])\n",
    "            else:\n",
    "                curq = None\n",
    "            self.quantizers_.append(curq)\n",
    "\n",
    "        X_train = []\n",
    "        Y_train = []\n",
    "        for dupix in range(self.duplicate_K):\n",
    "            mask_ixs = np.repeat(np.arange(n_dims)[np.newaxis, :], n_samples, axis=0)\n",
    "            mask_ixs = np.apply_along_axis(rng.permutation, axis=1, arr=mask_ixs) # n_samples, n_dims\n",
    "            for n in range(n_samples):\n",
    "                fuller_X = X[n, :]\n",
    "                for d in range(n_dims):\n",
    "                    victim_ix = mask_ixs[n, d]\n",
    "                    if fuller_X[victim_ix] != np.nan:\n",
    "                        emptier_X = fuller_X.copy()\n",
    "                        emptier_X[mask_ixs[n, d]] = np.nan\n",
    "                        X_train.append(emptier_X.reshape(1, -1))\n",
    "                        Y_train.append(fuller_X.reshape(1, -1))\n",
    "                        fuller_X = emptier_X\n",
    "        X_train = np.concatenate(X_train, axis=0)\n",
    "        Y_train = np.concatenate(Y_train, axis=0)\n",
    "        self.trees_ = []\n",
    "        for d in range(n_dims):\n",
    "            xgber = xgb.XGBClassifier(tree_method=\"hist\") # TODO: early_stopping_rounds=2)\n",
    "            train_ixs = ~np.isnan(Y_train[:, d])\n",
    "            if self.quantize_cols_[d]:\n",
    "                curY_train = self.quantizers_[d].transform(Y_train[train_ixs, d:d+1])\n",
    "            else:\n",
    "                curY_train = Y_train[train_ixs, d:d+1]\n",
    "            curX_train = X_train[train_ixs, :] \n",
    "            xgber.fit(curX_train, curY_train)  # TODO: sample_weight\n",
    "            self.trees_.append(xgber)\n",
    "        return self\n",
    "\n",
    "    def generate(\n",
    "        self,\n",
    "        n_samples=1,\n",
    "    ):\n",
    "        n_samples, n_dims = self.X_.shape\n",
    "        rng = check_random_state(self.random_state)\n",
    "\n",
    "        X = np.full(fill_value=np.nan, shape=(n_samples, n_dims))\n",
    "        unmask_ixs = np.repeat(np.arange(n_dims)[np.newaxis, :], n_samples, axis=0)  # (n_samples, n_dims)\n",
    "        unmask_ixs = np.apply_along_axis(rng.permutation, axis=1, arr=unmask_ixs) # (n_samples, n_dims)\n",
    "        for n in range(n_samples):\n",
    "            for dix in range(n_dims):\n",
    "                unmask_ix = unmask_ixs[n, dix]\n",
    "                pred_probas = self.trees_[unmask_ix].predict_proba(X[[n], :])\n",
    "                pred_quant = top_p_sampling(self.n_bins, pred_probas, rng, self.top_p)\n",
    "\n",
    "                if self.quantize_cols_[unmask_ix]:\n",
    "                    pred_val = self.quantizers_[unmask_ix].inverse_transform_sample(pred_quant.reshape(1, 1))\n",
    "                else:\n",
    "                    pred_val = pred_quant\n",
    "                X[n, unmask_ix] = pred_val.item()\n",
    "        return X\n",
    "\n",
    "    def impute(\n",
    "        self,\n",
    "        k=1,\n",
    "    ):\n",
    "        (n_samples, n_dims) = self.X_.shape\n",
    "        rng = check_random_state(self.random_state)\n",
    "\n",
    "        imputedX = np.repeat(self.X_[np.newaxis, :, :], repeats=k, axis=0) # (k, n_samples, n_dims)           \n",
    "        for n in range(n_samples):\n",
    "            to_unmask = np.where(np.isnan(self.X_[n, :]))[0] # (n_to_unmask,)\n",
    "            unmask_ixs = np.repeat(to_unmask[np.newaxis, :], k, axis=0)  # (k, n_to_unmask)\n",
    "            unmask_ixs = np.apply_along_axis(rng.permutation, axis=1, arr=unmask_ixs) # (k, n_to_unmask)\n",
    "            n_to_unmask = unmask_ixs.shape[1]\n",
    "            for kix in range(k):\n",
    "                for dix in range(n_to_unmask):\n",
    "                    unmask_ix = unmask_ixs[kix, dix]\n",
    "                    pred_probas = self.trees_[unmask_ix].predict_proba(imputedX[kix,[n], :])\n",
    "                    pred_quant = top_p_sampling(self.n_bins, pred_probas, rng, self.top_p)\n",
    "                    pred_val = self.quantizers_[unmask_ix].inverse_transform_sample(pred_quant.reshape(1, 1))\n",
    "                    imputedX[kix, n, unmask_ix] = pred_val.item()\n",
    "        return imputedX\n",
    "\n",
    "rix = 0\n",
    "rng = check_random_state(rix)\n",
    "n_upper = 100\n",
    "n_lower = 100\n",
    "n = n_upper + n_lower\n",
    "data, labels = skd.make_moons(\n",
    "    (n_upper, n_lower), shuffle=False, noise=0.1, random_state=rix)\n",
    "data4impute = data.copy()\n",
    "data4impute[:, 1] = np.nan\n",
    "X=np.concatenate([data, data4impute], axis=0)\n",
    "\n",
    "model = MaskingTreesModel(n_bins=20)\n",
    "model.fit(X)\n",
    "data_fake = model.generate(n_samples=200);\n",
    "\n",
    "\n",
    "\n",
    "nimp = 1 # number of imputations needed\n",
    "data_impute = model.impute(k=nimp)[0, :, :]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(7, 5));\n",
    "axes[0, 0].scatter(data[:, 0], data[:, 1]);\n",
    "axes[0, 0].set_title('original');\n",
    "axes[0, 1].scatter(data_fake[:, 0], data_fake[:, 1]);\n",
    "axes[0, 1].set_title('generated');\n",
    "axes[1, 0].scatter(data_impute[200:, 0], data_impute[200:, 1]);\n",
    "axes[1, 0].set_title('imputed');\n",
    "\"\"\"\n",
    "axes[1, 1].scatter(data_impute[200:, 0], data_impute[200:, 1]);\n",
    "axes[1, 1].set_title('imputed - repainted');\n",
    "\"\"\"\n",
    "plt.tight_layout();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56bbcbea-a2db-4dc3-b39f-3ef4a107eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[\"cat_feature\"].astype(\"category\")\n",
    "# clf = xgb.XGBClassifier(tree_method=\"hist\", enable_categorical=True, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "759c973e-69eb-4ae3-81ca-a90f6e1e629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "X = X[list(X.select_dtypes(include=['number']).columns)]# + ['sex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ce2dacb-c7cd-4687-b562-ed541ba60ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29.      0.9167  2.     ... 26.5    27.     29.    ]\n",
      "[211.3375 151.55   151.55   ...   7.225    7.225    7.875 ]\n",
      "[ nan  nan  nan ... 304.  nan  nan]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got [1. 2. 3.]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m MaskingTreesModel(n_bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[38], line 154\u001b[0m, in \u001b[0;36mMaskingTreesModel.fit\u001b[0;34m(self, X, quantize_cols)\u001b[0m\n\u001b[1;32m    152\u001b[0m         curY_train \u001b[38;5;241m=\u001b[39m Y_train[train_ixs, d:d\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    153\u001b[0m     curX_train \u001b[38;5;241m=\u001b[39m X_train[train_ixs, :] \n\u001b[0;32m--> 154\u001b[0m     \u001b[43mxgber\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurY_train\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# TODO: sample_weight\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees_\u001b[38;5;241m.\u001b[39mappend(xgber)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/maskingtrees/lib/python3.9/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/maskingtrees/lib/python3.9/site-packages/xgboost/sklearn.py:1491\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1486\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1488\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1489\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m   1490\u001b[0m ):\n\u001b[0;32m-> 1491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1492\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1493\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1494\u001b[0m     )\n\u001b[1;32m   1496\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got [1. 2. 3.]"
     ]
    }
   ],
   "source": [
    "model = MaskingTreesModel(n_bins=20)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77400b15-0860-4978-ac03-026e198a9def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>3</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>3</td>\n",
       "      <td>26.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>3</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass      age  sibsp  parch      fare   body\n",
       "0          1  29.0000      0      0  211.3375    NaN\n",
       "1          1   0.9167      1      2  151.5500    NaN\n",
       "2          1   2.0000      1      2  151.5500    NaN\n",
       "3          1  30.0000      1      2  151.5500  135.0\n",
       "4          1  25.0000      1      2  151.5500    NaN\n",
       "...      ...      ...    ...    ...       ...    ...\n",
       "1304       3  14.5000      1      0   14.4542  328.0\n",
       "1305       3      NaN      1      0   14.4542    NaN\n",
       "1306       3  26.5000      0      0    7.2250  304.0\n",
       "1307       3  27.0000      0      0    7.2250    NaN\n",
       "1308       3  29.0000      0      0    7.8750    NaN\n",
       "\n",
       "[1309 rows x 6 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18cff38f-ce00-4f14-8d5e-81356b55080a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.    ,  29.    ,   0.    ,   0.    , 211.3375,      nan],\n",
       "       [  1.    ,   0.9167,   1.    ,   2.    , 151.55  ,      nan],\n",
       "       [  1.    ,   2.    ,   1.    ,   2.    , 151.55  ,      nan],\n",
       "       ...,\n",
       "       [  3.    ,  26.5   ,   0.    ,   0.    ,   7.225 , 304.    ],\n",
       "       [  3.    ,  27.    ,   0.    ,   0.    ,   7.225 ,      nan],\n",
       "       [  3.    ,  29.    ,   0.    ,   0.    ,   7.875 ,      nan]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79bd961-2918-433b-bf0a-83a2287e39f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
