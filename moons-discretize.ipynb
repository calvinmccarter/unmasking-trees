{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d89dfd5-7692-45bc-b126-862b3cb0c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.datasets as skd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a7b0caa-a4ec-40ad-a1c8-107e73c66678",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_deprecate_Xt_in_inverse_transform' from 'sklearn.utils.deprecation' (/Users/calvinm/miniconda3/envs/maskingtrees/lib/python3.9/site-packages/sklearn/utils/deprecation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KBinsDiscretizer, LabelEncoder\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _deprecate_Xt_in_inverse_transform\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     _check_feature_names_in,\n\u001b[1;32m     11\u001b[0m     _check_sample_weight,\n\u001b[1;32m     12\u001b[0m     check_array,\n\u001b[1;32m     13\u001b[0m     check_is_fitted,\n\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_deprecate_Xt_in_inverse_transform' from 'sklearn.utils.deprecation' (/Users/calvinm/miniconda3/envs/maskingtrees/lib/python3.9/site-packages/sklearn/utils/deprecation.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import kditransform\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.preprocessing import KBinsDiscretizer, LabelEncoder\n",
    "from sklearn.utils.deprecation import _deprecate_Xt_in_inverse_transform\n",
    "from sklearn.utils.validation import (\n",
    "    _check_feature_names_in,\n",
    "    _check_sample_weight,\n",
    "    check_array,\n",
    "    check_is_fitted,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405ef799-cc19-4b01-b41e-24c1a29696d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KBinsDiscretizerSampler(KBinsDiscretizer):   \n",
    "    def inverse_transform_sample(self, X=None, random_state=None):\n",
    "        rng = check_random_state(random_state)\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        if \"onehot\" in self.encode:\n",
    "            X = self._encoder.inverse_transform(X)\n",
    "\n",
    "        Xinv = check_array(X, copy=True, dtype=(np.float64, np.float32))\n",
    "        n_features = self.n_bins_.shape[0]\n",
    "        if Xinv.shape[1] != n_features:\n",
    "            raise ValueError(\n",
    "                \"Incorrect number of features. Expecting {}, received {}.\".format(\n",
    "                    n_features, Xinv.shape[1]\n",
    "                )\n",
    "            )\n",
    "        n = X.shape[0]\n",
    "        for jj in range(n_features):\n",
    "            jitter = rng.uniform(0., 1., size=n)\n",
    "            bin_edges = self.bin_edges_[jj]\n",
    "            bin_centers = (bin_edges[1:] + bin_edges[:-1]) * 0.5\n",
    "            bin_lefts = bin_edges[1:][(Xinv[:, jj]).astype(np.int64)]\n",
    "            bin_rights = bin_edges[:-1][(Xinv[:, jj]).astype(np.int64)]\n",
    "            Xinv[:, jj] = bin_lefts * jitter + bin_rights * (1 - jitter)\n",
    "\n",
    "        return Xinv\n",
    "\n",
    "def top_p_sampling(n_bins, probs, rng, top_p):\n",
    "    \"\"\" This implements a modified version of nucleus sampling.\n",
    "    It discards probability mass beyond the boundary of the class straddles the top_p boundary,\n",
    "    but it does not discard the probability mass of this class below the boundary.\n",
    "    \"\"\"\n",
    "    probs = probs.ravel()  # currently assumes only one sample\n",
    "    sort_indices = np.argsort(probs)[::-1]\n",
    "    sort_probs = probs[sort_indices]\n",
    "    cumsum_probs = np.cumsum(sort_probs)\n",
    "    unnorm_probs = np.diff(np.minimum(cumsum_probs, top_p), prepend=0.)\n",
    "    unnorm_probs = unnorm_probs[np.argsort(sort_indices)]  # undo the sort\n",
    "    norm_probs = unnorm_probs / np.sum(unnorm_probs)\n",
    "    chosen = np.array(rng.choice(n_bins, p=norm_probs))\n",
    "    return chosen\n",
    "\n",
    "class MaskingTreesModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_bins=5,\n",
    "        duplicate_K=50,\n",
    "        top_p=0.9,\n",
    "        random_state = None,\n",
    "    ):\n",
    "        self.n_bins = n_bins\n",
    "        self.duplicate_K = duplicate_K\n",
    "        self.top_p = top_p\n",
    "        self.random_state = random_state\n",
    "\n",
    "        assert 2 <= n_bins\n",
    "        assert 1 <= duplicate_K\n",
    "        assert 0 < top_p <= 1\n",
    "    \n",
    "        self.xgbers_ = None\n",
    "        self.quantize_cols_ = None\n",
    "        self.quantizers_ = None\n",
    "        self.X_ = None\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        quantize_cols='all',\n",
    "    ):\n",
    "        # Tuesday: kditransformer, xgboost kwargs, move to script, then benchmark\n",
    "        # Wednesday: write up - table, moons, CA\n",
    "        # TODO - xgboost iterator - generate batches on the fly -- delay this\n",
    "        # TODO - parallel?\n",
    "        # TODO - xgboost kwargs\n",
    "        # TODO - sample_weight from OADM formula\n",
    "        # TODO - KDITransformer\n",
    "        rng = check_random_state(self.random_state)\n",
    "        assert isinstance(X, np.ndarray)\n",
    "        n_samples, n_dims = X.shape\n",
    "        if isinstance(quantize_cols, list):\n",
    "            assert len(quantize_cols) == n_dims\n",
    "            self.quantize_cols_ = quantize_cols\n",
    "        elif quantize_cols == 'none':\n",
    "            self.quantize_cols_ = [False] * n_dims\n",
    "        elif quantize_cols == 'all':\n",
    "            self.quantize_cols_ = [True] * n_dims\n",
    "        else:\n",
    "            raise ValueError(f'unexpected quantize_cols: {quantize_cols}')\n",
    "\n",
    "        self.X_ = X.copy()\n",
    "\n",
    "        \n",
    "        self.quantizers_ = []       \n",
    "        for d in range(n_dims):\n",
    "            if self.quantize_cols_[d]:\n",
    "                curq = KBinsDiscretizerSampler(\n",
    "                    n_bins=self.n_bins, encode='ordinal', strategy='quantile')\n",
    "                curq.fit(X[~np.isnan(X[:, d]), d:d+1])\n",
    "            else:\n",
    "                curq = LabelEncoder()\n",
    "                curq.fit(X[~np.isnan(X[:, d]), d])\n",
    "            self.quantizers_.append(curq)\n",
    "\n",
    "        X_train = []\n",
    "        Y_train = []\n",
    "        for dupix in range(self.duplicate_K):\n",
    "            mask_ixs = np.repeat(np.arange(n_dims)[np.newaxis, :], n_samples, axis=0)\n",
    "            mask_ixs = np.apply_along_axis(rng.permutation, axis=1, arr=mask_ixs) # n_samples, n_dims\n",
    "            for n in range(n_samples):\n",
    "                fuller_X = X[n, :]\n",
    "                for d in range(n_dims):\n",
    "                    victim_ix = mask_ixs[n, d]\n",
    "                    if fuller_X[victim_ix] != np.nan:\n",
    "                        emptier_X = fuller_X.copy()\n",
    "                        emptier_X[mask_ixs[n, d]] = np.nan\n",
    "                        X_train.append(emptier_X.reshape(1, -1))\n",
    "                        Y_train.append(fuller_X.reshape(1, -1))\n",
    "                        fuller_X = emptier_X\n",
    "        X_train = np.concatenate(X_train, axis=0)\n",
    "        Y_train = np.concatenate(Y_train, axis=0)\n",
    "        self.trees_ = []\n",
    "        for d in range(n_dims):\n",
    "            xgber = xgb.XGBClassifier(tree_method=\"hist\") # TODO: early_stopping_rounds=2)\n",
    "            print(xgber.objective)\n",
    "            train_ixs = ~np.isnan(Y_train[:, d])\n",
    "            if self.quantize_cols_[d]:\n",
    "                curY_train = self.quantizers_[d].transform(Y_train[train_ixs, d:d+1])\n",
    "            else:\n",
    "                curY_train = self.quantizers_[d].transform(Y_train[train_ixs, d])\n",
    "            curX_train = X_train[train_ixs, :] \n",
    "            xgber.fit(curX_train, curY_train)  # TODO: sample_weight\n",
    "            self.trees_.append(xgber)\n",
    "        return self\n",
    "\n",
    "    def generate(\n",
    "        self,\n",
    "        n_samples=1,\n",
    "    ):\n",
    "        n_samples, n_dims = self.X_.shape\n",
    "        rng = check_random_state(self.random_state)\n",
    "\n",
    "        X = np.full(fill_value=np.nan, shape=(n_samples, n_dims))\n",
    "        unmask_ixs = np.repeat(np.arange(n_dims)[np.newaxis, :], n_samples, axis=0)  # (n_samples, n_dims)\n",
    "        unmask_ixs = np.apply_along_axis(rng.permutation, axis=1, arr=unmask_ixs) # (n_samples, n_dims)\n",
    "        for n in range(n_samples):\n",
    "            for dix in range(n_dims):\n",
    "                unmask_ix = unmask_ixs[n, dix]\n",
    "                pred_probas = self.trees_[unmask_ix].predict_proba(X[[n], :])\n",
    "                cur_quant = self.quantizers_[unmask_ix]\n",
    "                if self.quantize_cols_[unmask_ix]:\n",
    "                    pred_quant = top_p_sampling(cur_quant.n_bins_[0], pred_probas, rng, self.top_p)\n",
    "                    pred_val = cur_quant.inverse_transform_sample(pred_quant.reshape(1, 1))\n",
    "                else:\n",
    "                    pred_quant = top_p_sampling(len(cur_quant.classes_), pred_probas, rng, self.top_p)\n",
    "                    pred_val = cur_quant.inverse_transform(pred_quant.reshape(1,))\n",
    "                X[n, unmask_ix] = pred_val.item()\n",
    "        return X\n",
    "\n",
    "    def impute(\n",
    "        self,\n",
    "        k=1,\n",
    "    ):\n",
    "        (n_samples, n_dims) = self.X_.shape\n",
    "        rng = check_random_state(self.random_state)\n",
    "\n",
    "        imputedX = np.repeat(self.X_[np.newaxis, :, :], repeats=k, axis=0) # (k, n_samples, n_dims)           \n",
    "        for n in range(n_samples):\n",
    "            to_unmask = np.where(np.isnan(self.X_[n, :]))[0] # (n_to_unmask,)\n",
    "            unmask_ixs = np.repeat(to_unmask[np.newaxis, :], k, axis=0)  # (k, n_to_unmask)\n",
    "            unmask_ixs = np.apply_along_axis(rng.permutation, axis=1, arr=unmask_ixs) # (k, n_to_unmask)\n",
    "            n_to_unmask = unmask_ixs.shape[1]\n",
    "            for kix in range(k):\n",
    "                for dix in range(n_to_unmask):\n",
    "                    unmask_ix = unmask_ixs[kix, dix]\n",
    "                    pred_probas = self.trees_[unmask_ix].predict_proba(imputedX[kix,[n], :])\n",
    "                    print(pred_probas, pred_probas.sum())\n",
    "                    return imputedX\n",
    "                    cur_quant = self.quantizers_[unmask_ix]\n",
    "                    if self.quantize_cols_[unmask_ix]:\n",
    "                        pred_quant = top_p_sampling(cur_quant.n_bins_[0], pred_probas, rng, self.top_p)\n",
    "                        pred_val = cur_quant.inverse_transform_sample(pred_quant.reshape(1, 1))\n",
    "                    else:\n",
    "                        pred_quant = top_p_sampling(len(cur_quant.classes_), pred_probas, rng, self.top_p)\n",
    "                        pred_val = cur_quant.inverse_transform(pred_quant.reshape(1,))\n",
    "                    imputedX[kix, n, unmask_ix] = pred_val.item()\n",
    "        return imputedX\n",
    "\n",
    "rix = 0\n",
    "rng = check_random_state(rix)\n",
    "n_upper = 100\n",
    "n_lower = 100\n",
    "n = n_upper + n_lower\n",
    "data, labels = skd.make_moons(\n",
    "    (n_upper, n_lower), shuffle=False, noise=0.1, random_state=rix)\n",
    "data4impute = data.copy()\n",
    "data4impute[:, 1] = np.nan\n",
    "X=np.concatenate([data, data4impute], axis=0)\n",
    "\n",
    "model = MaskingTreesModel(n_bins=20)\n",
    "model.fit(X)\n",
    "data_fake = model.generate(n_samples=200);\n",
    "\n",
    "\n",
    "nimp = 1 # number of imputations needed\n",
    "data_impute = model.impute(k=nimp)[0, :, :]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(7, 5));\n",
    "axes[0, 0].scatter(data[:, 0], data[:, 1]);\n",
    "axes[0, 0].set_title('original');\n",
    "axes[0, 1].scatter(data_fake[:, 0], data_fake[:, 1]);\n",
    "axes[0, 1].set_title('generated');\n",
    "axes[1, 0].scatter(data_impute[200:, 0], data_impute[200:, 1]);\n",
    "axes[1, 0].set_title('imputed');\n",
    "\"\"\"\n",
    "axes[1, 1].scatter(data_impute[200:, 0], data_impute[200:, 1]);\n",
    "axes[1, 1].set_title('imputed - repainted');\n",
    "\"\"\"\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bbcbea-a2db-4dc3-b39f-3ef4a107eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[\"cat_feature\"].astype(\"category\")\n",
    "# clf = xgb.XGBClassifier(tree_method=\"hist\", enable_categorical=True, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759c973e-69eb-4ae3-81ca-a90f6e1e629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "X = X[list(X.select_dtypes(include=['number']).columns)]# + ['sex']]\n",
    "model = MaskingTreesModel(n_bins=5, duplicate_K=10)\n",
    "quantize_cols = [\n",
    "    col in list(X.select_dtypes(include=['floating']).columns)\n",
    "    for col in X.columns]\n",
    "model.fit(X.values, quantize_cols=quantize_cols)\n",
    "model.generate(n_samples=1)\n",
    "model.fit(X.values)\n",
    "model.generate(n_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79bd961-2918-433b-bf0a-83a2287e39f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "my_data = load_iris()\n",
    "X, y = my_data['data'], my_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6bb0d5-c4af-418b-a4e4-543b08a8fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'asdf': 4}.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6efa1582-8e66-4328-a325-c27fbc416435",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "844f63af-e339-430d-af46-3d707fdff74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e66f0d5c-7075-43e3-85da-d92c84b57a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calvinm/miniconda3/envs/maskingtrees/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(np.array([[1,]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "165e9efc-3608-4300-9b9e-7a3897b3aeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be813c2a-a8bd-4976-b243-43a398ec8870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bdcdfc-0153-4284-b1e9-840f041de45b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
